{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpH8UqvF1LRj"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Dataset.csv')"
      ],
      "metadata": {
        "id": "aEp8923K1Zhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of the dataset: ' + str(dataset.shape))\n",
        "print(dataset.head())"
      ],
      "metadata": {
        "id": "wuhnJU_F2L9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979fe58a-b213-43be-ac72-18fe77ea314a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataset: (380, 17)\n",
            "   FTHG  FTAG  HTHG  HTAG  HS  AS  HST  AST  HF  AF  HC  AC  HY  AY  HR  AR  \\\n",
            "0     3     0     2     0  23  12   11    2  15  15  16   7   1   2   0   0   \n",
            "1     1     0     1     0   7  17    2   12  19  14   1   3   2   1   0   0   \n",
            "2     0     0     0     0  13  12    9    7  12  13   4   8   1   3   0   0   \n",
            "3     6     0     2     0  18  10   13    4  10  10   3   1   1   0   0   0   \n",
            "4     2     2     1     0   6  13    2    7  13  10   3   6   3   3   1   0   \n",
            "\n",
            "  FTR  \n",
            "0   H  \n",
            "1   H  \n",
            "2   D  \n",
            "3   H  \n",
            "4   D  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the dependent variable class\n",
        "factor = pd.factorize(dataset['FTR'])\n",
        "dataset.FTR = factor[0]\n",
        "definitions = factor[1]\n",
        "print(dataset.FTR.head())\n",
        "print(definitions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKgUZAae3QVD",
        "outputId": "f24bf3a2-2cd0-47d3-d820-7a05500eadea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    0\n",
            "4    1\n",
            "Name: FTR, dtype: int64\n",
            "Index(['H', 'D', 'A'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into independent and dependent variables\n",
        "X = dataset.iloc[:,0:16].values\n",
        "y = dataset.iloc[:,16].values\n",
        "print('The independent features set: ')\n",
        "print(X[:17,:])\n",
        "print('The dependent variable: ')\n",
        "print(y[:17])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf5PInYL3yen",
        "outputId": "22c9811d-a2e4-4b75-9daf-1d0edbea8b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The independent features set: \n",
            "[[ 3  0  2  0 23 12 11  2 15 15 16  7  1  2  0  0]\n",
            " [ 1  0  1  0  7 17  2 12 19 14  1  3  2  1  0  0]\n",
            " [ 0  0  0  0 13 12  9  7 12 13  4  8  1  3  0  0]\n",
            " [ 6  0  2  0 18 10 13  4 10 10  3  1  1  0  0  0]\n",
            " [ 2  2  1  0  6 13  2  7 13 10  3  6  3  3  1  0]\n",
            " [ 0  0  0  0 22 11 18  7 13 16 10  3  0  2  0  0]\n",
            " [ 0  4  0  3 11  9  6  7  8 11  6  4  1  1  0  0]\n",
            " [ 2  1  2  0 13 10  7  6 17 13  5  5  0  2  0  0]\n",
            " [ 1  1  0  0  7 14  4  7 13 15  9 11  1  3  1  1]\n",
            " [ 3  0  2  0 18  7 10  3  9  5  5  3  2  2  0  0]\n",
            " [ 6  0  3  0 26  3 16  1  9  3  8  2  0  0  0  1]\n",
            " [ 2  1  0  0 10  7  7  2 13 14  4 12  2  3  0  0]\n",
            " [ 1  1  1  0 14  9  6  4 18 15  3  3  1  2  0  0]\n",
            " [ 1  2  1  2 15  7 10  6 15  4  6  2  3  1  0  0]\n",
            " [ 1  0  0  0 11 10  5  4 16 12  4  6  2  2  0  0]\n",
            " [ 1  3  0  0 17 12 10  8 11 18  8  5  2  4  0  0]\n",
            " [ 0  6  0  1 17 10 12  8 12  7  0  0  1  2  0  0]]\n",
            "The dependent variable: \n",
            "[0 0 1 0 1 1 2 0 1 0 0 0 1 2 0 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Training and Test set from data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)"
      ],
      "metadata": {
        "id": "vBYuAcAW4PDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "tOyqE5W94XCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting Random Forest Classification to the Training set\n",
        "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww4MsSfJ4bvw",
        "outputId": "6cd66ecd-a6d3-4b78-e502-95495038596e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "#Reverse factorize (converting y_pred from 0s,1s and 2s to H, D and A\n",
        "reversefactor = dict(zip(range(3),definitions))\n",
        "y_test = np.vectorize(reversefactor.get)(y_test)\n",
        "y_pred = np.vectorize(reversefactor.get)(y_pred)"
      ],
      "metadata": {
        "id": "zwO602ZK44L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the Confusion Matrix\n",
        "print(pd.crosstab(y_test, y_pred, rownames=['Actual Output'], colnames=['Predicted Output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VXRL7ej5P7D",
        "outputId": "e6b82292-b588-44d6-bb10-c2e945aaf534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Output   A   D   H\n",
            "Actual Output               \n",
            "A                 25   3   0\n",
            "D                  0  23   4\n",
            "H                  0   0  40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UOrctVV65eZc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}